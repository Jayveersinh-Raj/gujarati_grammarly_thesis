{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3398ce4f-ead3-451e-8528-905601c5db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/root/.cache/huggingface/datasets/autopilot-ai___csv/autopilot-ai--Gujarati-Grammarly-Datasets-7432f8bd995d09c0/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"autopilot-ai/Gujarati-Grammarly-Datasets\",data_files=[\"sentence-pairs/gujarati_sentences_1M.csv\"], split = \"train[100000:110000]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e775444c-d2fd-4873-946b-417503443ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Correct', 'Incorrect'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e112563-e172-455f-91a2-106e1642ed5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Correct': 'ત્યાં કોઈ કારણ નથી કે શા માટે વધુ રમતો દૈનિક સ્તરોના જોડાણ-પ્રેરિત હૂકનો ઉપયોગ કરી શકતા નથી.',\n",
       " 'Incorrect': 'ત્યાં કૌઇ કારણ નથી કૈ શા માતૈ વધુ રમતો દૈનિક સ્તરોના જોડાણ-પ્રેરિત હૂકનો ઉપયોગ કરી શકતા નથી.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f248ed19-13f5-4f7e-9c43-7b22aaa409e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /usr/local/lib/python3.8/dist-packages/bitsandbytes/libbitsandbytes_cuda115.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 115\n",
      "CUDA SETUP: Loading binary /usr/local/lib/python3.8/dist-packages/bitsandbytes/libbitsandbytes_cuda115.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "Downloading tokenizer_config.json: 100%|██████████| 303/303 [00:00<00:00, 36.1kB/s]\n",
      "Downloading spiece.model: 100%|██████████| 4.31M/4.31M [00:00<00:00, 6.46MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 16.3M/16.3M [00:01<00:00, 13.6MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 74.0/74.0 [00:00<00:00, 19.5kB/s]\n",
      "Downloading config.json: 100%|██████████| 829/829 [00:00<00:00, 577kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 4.92G/4.92G [06:02<00:00, 13.6MB/s]\n",
      "Downloading generation_config.json: 100%|██████████| 142/142 [00:00<00:00, 20.9kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "checkpoint = \"Jayveersinh-Raj/guj-grammar-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "816fb83a-dac0-4e0b-86e4-eea7775e7c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MT5ForConditionalGeneration(\n",
       "  (shared): Embedding(250112, 1024)\n",
       "  (encoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=250112, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c77dba8-da32-4cb2-ac39-2ad356a9e2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: શિયાળાની ઠંડી હોય તો મોટાભાગના લોકોને શરદી, ઉધરસ અને છીંક આવવાની ટકલિફ હૌય છે.\n",
      "Generated Sentence: શિયાળાની ઠંડી હોય તો મોટાભાગના લોકોને શરદી, ઉધરસ અને છીંક આવવાની તર્કીલ હોય છે.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Input sentence for prediction\n",
    "input_sentence = \"શિયાળાની ઠંડી હોય તો મોટાભાગના લોકોને શરદી, ઉધરસ અને છીંક આવવાની ટકલિફ હૌય છે.\"\n",
    "\n",
    "# Tokenize the input sentence\n",
    "input_ids = tokenizer.encode(input_sentence, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(input_ids, max_new_tokens=200)\n",
    "\n",
    "# Decode the generated output\n",
    "output_sentence = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated output\n",
    "print(\"Input Sentence:\", input_sentence)\n",
    "print(\"Generated Sentence:\", output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d8ec501-de71-4d87-8263-e284d6f3065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|██████████| 10000/10000 [3:59:08<00:00,  1.43s/it] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Sentence</th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>Generated Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>તે એક સુરક્ષાકર્મી હતો.</td>\n",
       "      <td>તે એક સુરક્ષાકર્મી હતો.</td>\n",
       "      <td>તે એક સુરક્ષાકર્મી હતો.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>મોટેભાગે, ગુલામોનું પણ વેપાર થાય છે.</td>\n",
       "      <td>મોટેભાગે, ગુલામોનું પણ વેપાર થાય છે.</td>\n",
       "      <td>મોટાભાગે, ગુલામોનું પણ વેપાર થાય છે.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ત્યાં કૌઇ કારણ નથી કૈ શા માતૈ વધુ રમતો દૈનિક સ...</td>\n",
       "      <td>ત્યાં કોઈ કારણ નથી કે શા માટે વધુ રમતો દૈનિક સ...</td>\n",
       "      <td>ત્યાં કોઈ કારણ નથી કે શા માટે વધુ રમતો દૈનિક સ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>હૂઁ વધૂ કંઇ નથી કહી શકતો કારણ કે તેમનો ટ્રેક ટ...</td>\n",
       "      <td>હું વધુ કંઇ નથી કહી શકતો કારણ કે તેમનો ટ્રેક ત...</td>\n",
       "      <td>હું વધુ કંઇ નથી કહી શકતો કારણ કે તેમનો ટ્રેક ત...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ઉદાહરણ તરીકે, લખો ઝીરો ફક્ત ડેટા પર ઝૂરો લખે છ...</td>\n",
       "      <td>ઉદાહરણ તરીકે, લખો ઝીરો ફક્ત ડેટા પર ઝૂરો લખે છ...</td>\n",
       "      <td>લખો ઝીરો ફક્ત ડેટા પર ઝૂરો લખે છે અને રેન્ડમ ડ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Input Sentence  \\\n",
       "0                            તે એક સુરક્ષાકર્મી હતો.   \n",
       "1               મોટેભાગે, ગુલામોનું પણ વેપાર થાય છે.   \n",
       "2  ત્યાં કૌઇ કારણ નથી કૈ શા માતૈ વધુ રમતો દૈનિક સ...   \n",
       "3  હૂઁ વધૂ કંઇ નથી કહી શકતો કારણ કે તેમનો ટ્રેક ટ...   \n",
       "4  ઉદાહરણ તરીકે, લખો ઝીરો ફક્ત ડેટા પર ઝૂરો લખે છ...   \n",
       "\n",
       "                                        Ground Truth  \\\n",
       "0                            તે એક સુરક્ષાકર્મી હતો.   \n",
       "1               મોટેભાગે, ગુલામોનું પણ વેપાર થાય છે.   \n",
       "2  ત્યાં કોઈ કારણ નથી કે શા માટે વધુ રમતો દૈનિક સ...   \n",
       "3  હું વધુ કંઇ નથી કહી શકતો કારણ કે તેમનો ટ્રેક ત...   \n",
       "4  ઉદાહરણ તરીકે, લખો ઝીરો ફક્ત ડેટા પર ઝૂરો લખે છ...   \n",
       "\n",
       "                                  Generated Sentence  \n",
       "0                            તે એક સુરક્ષાકર્મી હતો.  \n",
       "1               મોટાભાગે, ગુલામોનું પણ વેપાર થાય છે.  \n",
       "2  ત્યાં કોઈ કારણ નથી કે શા માટે વધુ રમતો દૈનિક સ...  \n",
       "3  હું વધુ કંઇ નથી કહી શકતો કારણ કે તેમનો ટ્રેક ત...  \n",
       "4  લખો ઝીરો ફક્ત ડેટા પર ઝૂરો લખે છે અને રેન્ડમ ડ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Create lists to store input, ground truth, and generated sentences\n",
    "input_sentences = []\n",
    "ground_truth_sentences = []\n",
    "generated_sentences = []\n",
    "\n",
    "# Iterate through the dataset\n",
    "for example in tqdm(dataset, desc=\"Generating predictions\"):\n",
    "    # Assuming 'Incorrect' is the key for incorrect sentences\n",
    "    input_sentence = example['Incorrect']\n",
    "    \n",
    "    # Tokenize the input sentence\n",
    "    input_ids = tokenizer.encode(input_sentence, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate predictions\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(input_ids, max_new_tokens=200)\n",
    "\n",
    "    # Decode the generated output\n",
    "    generated_sentence = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Append to lists\n",
    "    input_sentences.append(input_sentence)\n",
    "    ground_truth_sentences.append(example['Correct'])\n",
    "    generated_sentences.append(generated_sentence)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Input Sentence': input_sentences,\n",
    "    'Ground Truth': ground_truth_sentences,\n",
    "    'Generated Sentence': generated_sentences\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69162d48-aa0c-4185-a7e6-84ccbcc735c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input Sentence        સલમાન ખાનનિ 29 વર્ષ જૂની હિરૌઇન આજે પણ એટલી જ ...\n",
       "Ground Truth          સલમાન ખાનની 29 વર્ષ જૂની હીરોઈન આજે પણ એટલી જ ...\n",
       "Generated Sentence    સલમાન ખાનની 29 વર્ષ જૂની હિરોઇન આજે પણ એટલી જ ...\n",
       "Name: 9, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "733ad9e0-9fcb-4afe-8be8-1c7df2f65ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting numba\n",
      "  Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 851 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting llvmlite<0.42,>=0.41.0dev0\n",
      "  Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 43.6 MB 9.8 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from numba) (6.7.0)\n",
      "Requirement already satisfied: numpy<1.27,>=1.22 in /usr/local/lib/python3.8/dist-packages (from numba) (1.24.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata; python_version < \"3.9\"->numba) (3.15.0)\n",
      "Installing collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.41.1 numba-0.58.1\n"
     ]
    }
   ],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7332ddd-dd5e-4032-b980-05f2207b857d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x7f39ab1b2ea0 to Device at 0x7f39ab1e16a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(1)\n",
    "cuda.close()\n",
    "cuda.select_device(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
